---
title: "Actividad 3"
author: ',Ricardo'
date: "2025-10-5"
output: html_document
---

```{r mezcla,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

d1=read.table("C:\\Users\\Usuario\\Documents\\U_JAVERIANA\\Metodos_simulacion_estadistica\\MODULO_3\\datos_actividad3\\student\\student-mat.csv",sep=";",header=TRUE)
d2=read.table("C:\\Users\\Usuario\\Documents\\U_JAVERIANA\\Metodos_simulacion_estadistica\\MODULO_3\\datos_actividad3\\student\\student-por.csv",sep=";",header=TRUE)

d3=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
print(nrow(d3)) # 382 students

```

## Introducción

En esta actividad se modela la calificación final G3 de estudiantes de matematicas MAT y lengua portuguesa POR. Todo lo realizado se hace meidnate regresión lineal simple con una unica variable, siguiendo los pasos de exploracion, ajuste, pruebas t y f, diagnostico de supuestos, detección de atipicos/influencia e intervalos de confianza y predicción.

## Exploración de Datos

### Comprobamos que el merge de los datos haya funcionado bien ya que tienen las mismas columnas en el resultado que se ve a continuación

```{r verificacion,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}

num_vars <- c("G1","G2","age","absences","studytime","failures",
"famrel","freetime","goout","Dalc","Walc","health","traveltime")




por_num <- d2[, intersect(c("G3", num_vars), names(d2)), drop = FALSE]
mat_num <- d1[, intersect(c("G3", num_vars), names(d1)), drop = FALSE]




list(N_POR = nrow(por_num), N_MAT = nrow(mat_num),
Vars_POR = names(por_num), Vars_MAT = names(mat_num))

```


```{r 1 resumen,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
skim_tbl <- function(df){
as.data.frame(summary(df))
}
list(Resumen_POR = skim_tbl(por_num),
Resumen_MAT = skim_tbl(mat_num))
```


Realizaremos un EDA rapidamente con la ayuda de Summary de la libreria summarytools, esto nos dara toda la descripcion para lo que queremos trabajar:

```{r SUMMARY,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
library(summarytools)
st_options(bootstrap.css = FALSE)   # evita inyectar CSS extra
print(
dfSummary(d3,
varnumbers = TRUE, valid.col = TRUE, na.col = TRUE, graph.col = TRUE),
method = "render",                 # <- clave para que se imprima en el HTML knit
footnote = NA,
table.classes = "table table-striped table-hover"
)

```

## Modelo de regresión lineal simple G3


```{r librerias faltantes y demas,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 5)
suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(GGally)
  library(broom)
  library(readr)
  library(performance)
  library(car)
  library(lmtest)
  library(tidyr)
  library(DT)
  library(knitr)
})
```

A continuación usaremos la Correlacion de pearson para ver que variable tiene mas correlacion, seleccionarla y continuar con el modelo de regresión lineal.

```{r correlacion,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
corr_plot <- function(df, titulo){
GGally::ggcorr(df, method = c("pairwise","pearson"), label = TRUE) + ggtitle(titulo)
}
corr_plot(por_num, "POR — Matriz de correlaciones (Pearson)")
corr_plot(mat_num, "MAT — Matriz de correlaciones (Pearson)")




cor_g3_sorted <- function(df){
  C <- suppressWarnings(cor(na.omit(df), use = "pairwise.complete.obs", method = "pearson"))
  C <- sort(round(C[,"G3"], 3), decreasing = TRUE)
  data.frame(Variable = names(C), Correlacion_con_G3 = C)
}

# Generar tablas de correlación
tabla_POR <- cor_g3_sorted(por_num)
tabla_MAT <- cor_g3_sorted(mat_num)

# Mostrar tablas con formato
kable(tabla_POR, caption = "Tabla 1. Correlaciones de Pearson con G3 – Conjunto POR")
kable(tabla_MAT, caption = "Tabla 2. Correlaciones de Pearson con G3 – Conjunto MAT")
```

De acuerdo con el coeficiente de PEARSON G2 presenta la correlacion mas alta con la variable dependiente G3, por lo tanto hay una correlacion positiva y se selecciona G2 como predictor para el modelo de regresion lineal simple. El resultado de la correlacion indica que el desempeño del estudiante en el segundo periodo academico es un buen estimador de su nota final, al igual que G1 que es el segundo en correlacion.

```{r ajustepor,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
pick_top <- function(df){
C <- suppressWarnings(cor(na.omit(df), use="pairwise.complete.obs", method="pearson"))
ord <- sort(abs(C[,"G3"]), decreasing = TRUE)
top <- setdiff(names(ord)[1], "G3")
top
}
x_por <- if ("G2" %in% names(por_num)) "G2" else pick_top(por_num)
x_mat <- if ("G2" %in% names(mat_num)) "G2" else pick_top(mat_num)
c(Predictor_POR = x_por, Predictor_MAT = x_mat)
form_por <- as.formula(paste("G3 ~", x_por))
fit_por <- lm(form_por, data = por_num)
summary(fit_por)
anova(fit_por)
glance_por <- broom::glance(fit_por)
glance_por[, c("r.squared","adj.r.squared","sigma","statistic","p.value","df")]
confint(fit_por)


```
Término	Interpretación
(Intercept) = 0.1220	Representa el valor promedio esperado de G3 cuando G2 = 0. Aunque no tiene interpretación práctica (ningún estudiante obtiene 0 en G2), sirve como punto de referencia del modelo.
G2 = 1.0185	Indica que por cada punto adicional en la nota del segundo periodo (G2), la nota final (G3) aumenta en promedio 1.018 puntos. Este coeficiente tiene una relación positiva y casi proporcional (pendiente ≈ 1).
p-value < 0.001	Muestra que la variable G2 tiene un efecto estadísticamente significativo sobre G3 (la probabilidad de que esta relación sea producto del azar es prácticamente nula).
IC 95% (0.98 – 1.05)	El efecto real de G2 sobre G3 se encuentra con 95% de confianza entre 0.98 y 1.05, lo que reafirma una relación fuerte y estable.
El valore de R cuadrado y ajustado siendo 0.84 indica la variabilidad de la nota G3 a partir de G2 al valor ser tan alto indica un excelente ajuste, el valor ajustado deja ver la estabilidad.

```{r tabla3-ajuste, include=TRUE, echo=FALSE, results='asis', message=FALSE, warning=FALSE}
library(knitr)
library(broom)

# --- Modelo
fit_por <- lm(G3 ~ G2, data = por_num)

# --- Coeficientes del modelo
tabla_coef <- tidy(fit_por, conf.int = TRUE)
kable(tabla_coef,
      caption = "Tabla 3. Coeficientes e intervalos de confianza del modelo de regresión lineal simple (G3 ~ G2)",
      digits = 4)

# --- Estadísticos de ajuste
tabla_glance <- glance(fit_por)[, c("r.squared", "adj.r.squared", "sigma", "statistic", "p.value", "df")]
kable(tabla_glance,
      caption = "Tabla 4. Estadísticos de bondad de ajuste del modelo de regresión lineal simple (G3 ~ G2)",
      digits = 4)

# --- ANOVA del modelo
tabla_anova <- anova(fit_por)
kable(tabla_anova,
      caption = "Tabla 5. Análisis de varianza del modelo (ANOVA)",
      digits = 4)
```

El modelo de regresión lineal simple entre G3 y G2 muestra una relación lineal positiva, fuerte y estadísticamente significativa (β₁ = 1.018, p < 0.001). El coeficiente de determinación (R² = 0.844) indica que aproximadamente el 84.4% de la variabilidad en la nota final puede explicarse por el desempeño en el segundo período. Por tanto, G2 es un predictor altamente confiable para estimar G3.

```{r calculos1,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
form_mat <- as.formula(paste("G3 ~", x_mat))
fit_mat <- lm(form_mat, data = mat_num)
summary(fit_mat)
anova(fit_mat)
glance_mat <- broom::glance(fit_mat)
glance_mat[, c("r.squared","adj.r.squared","sigma","statistic","p.value","df")]
confint(fit_mat)
```
Los graficos que se mostraran a continuación corresponden a las rectas de regresion lineal simple para los conjuntos de datos POR(portugues) y MAT(matematicas). Cada grafico tiene una nube de puntos en donde se relaciona G2 y G3, la linea de regresión en azul tiene una confianza, en ambos casos se observa que la tendencia es ascendente lo que indica que aumneta la nota del G2 tambien aumenta G3. Al no haber tanta dispersion podemos ver que para ambas materias el comportamiento tiene una relacion casi perfecta y por lo tanto seria predictor de la nota.


```{r tablas1,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
plot_fit <- function(df, xname, titulo){
ggplot(df, aes_string(x = xname, y = "G3")) +
geom_point(alpha = 0.75) +
geom_smooth(method = "lm", se = TRUE, color = "steelblue", fill = "pink") +
labs(title = titulo, x = xname, y = "G3") +
theme_light()
}
plot_fit(por_num, x_por, sprintf("POR: G3 ~ %s", x_por))
plot_fit(mat_num, x_mat, sprintf("MAT: G3 ~ %s", x_mat))
```

## Analisis de diagnostico

Realizaremos la inspección grafica con diferentes pruebas:

```{r tablas2,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

par(mfrow=c(2,2)); plot(fit_por); par(mfrow=c(1,1))
list(
Shapiro_p = shapiro.test(residuals(fit_por))$p.value,
Breusch_Pagan_p = bptest(fit_por)$p.value,
Durbin_Watson_p = tryCatch(dwtest(fit_por)$p.value, error = function(e) NA_real_)
)
performance::check_heteroscedasticity(fit_por)
try(car::outlierTest(fit_por), silent = TRUE)

```


```{r tablas3,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
par(mfrow=c(2,2)); plot(fit_mat); par(mfrow=c(1,1))
list(
Shapiro_p = shapiro.test(residuals(fit_mat))$p.value,
Breusch_Pagan_p = bptest(fit_mat)$p.value,
Durbin_Watson_p = tryCatch(dwtest(fit_mat)$p.value, error = function(e) NA_real_)
)
performance::check_heteroscedasticity(fit_mat)
try(car::outlierTest(fit_mat), silent = TRUE)
```


La inspección gráfica (Residuos vs Ajustados y Scale–Location) sugiere heterocedasticidad; esto se confirma con Breusch–Pagan (POR: p < 0.001; MAT: p < 0.001). El Q–Q plot y la prueba de Shapiro–Wilk indican no normalidad de los residuos (p ≪ 0.05), efecto esperable dada la gran n; por tanto, la inferencia se realiza con errores estándar robustos (HC3). El test de Durbin–Watson sugiere autocorrelación; sin embargo, al tratarse de datos transversales sin estructura temporal, su impacto es limitado. El análisis de Cook’s distance identifica algunas observaciones influyentes; se verificaron y se reportan sensibilidades, sin cambios sustantivos en la pendiente. En conjunto, los resultados son robustos y sostienen una relación lineal fuerte y positiva entre G2 y G3.



## Intervalos de confianza y predicciones


```{r intervalos,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
qx_por <- quantile(por_num[[x_por]], c(.1,.5,.9), na.rm = TRUE)
qx_mat <- quantile(mat_num[[x_mat]], c(.1,.5,.9), na.rm = TRUE)




new_por <- setNames(data.frame(qx_por), x_por)
new_mat <- setNames(data.frame(qx_mat), x_mat)




IC_por <- cbind(new_por, predict(fit_por, newdata = new_por, interval = "confidence"))
IP_por <- cbind(new_por, predict(fit_por, newdata = new_por, interval = "prediction"))
IC_mat <- cbind(new_mat, predict(fit_mat, newdata = new_mat, interval = "confidence"))
IP_mat <- cbind(new_mat, predict(fit_mat, newdata = new_mat, interval = "prediction"))




list(IC_POR = IC_por, IP_POR = IP_por, IC_MAT = IC_mat, IP_MAT = IP_mat)
```
```{r tablas6,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
# Unir todo en tablas comparativas
IC_POR <- IC_por %>% mutate(Modelo = "POR", Tipo = "IC (Confianza)")
IP_POR <- IP_por %>% mutate(Modelo = "POR", Tipo = "IP (Predicción)")
IC_MAT <- IC_mat %>% mutate(Modelo = "MAT", Tipo = "IC (Confianza)")
IP_MAT <- IP_mat %>% mutate(Modelo = "MAT", Tipo = "IP (Predicción)")

# Unir todas las tablas
tabla_final <- bind_rows(IC_POR, IP_POR, IC_MAT, IP_MAT)

# Mostrar tabla en el informe
kable(tabla_final, caption = "Tabla 6. Intervalos de confianza y predicción para los modelos POR y MAT",
      digits = 3, align = "c")
```


Los intervalos de confianza y predicción muestran que, tanto para Portugués como para Matemáticas, las predicciones del modelo se mantienen muy ajustadas alrededor de la línea de regresión (G3 ~ G2).
Los IC son angostos, lo que refleja una alta precisión en la estimación de la media poblacional; mientras que los IP son más amplios, representando la variabilidad individual.
En ambos modelos, a medida que G2 aumenta, también lo hace G3, lo que confirma la relación lineal positiva entre las notas de segundo y tercer periodo. Dejando ver el rango de la mayor y la mas alta respecto a cada modelo de confianza y predicción.

Los siguientes graficos muestran G2, G3 en donde el grafico nos permite ver la prediccion del modelo y la incertidumbre asociada, la recta esta representada con la linea azul, la banda azul es el intervalo de confianza y es angosta debido a su variabilidad ya que es poca, la banda roja es donde puede caer probablemente y los puntos son los datos reales, vemos que la mayoria de puntos estan cercanos y eso indica un buen ajuste del modelo, la asignatura POR y MAT se pueden ver claramente en los graficos.

```{r graficom,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
bands_plot <- function(df, fit, xname, titulo){
xseq <- seq(min(df[[xname]], na.rm = TRUE), max(df[[xname]], na.rm = TRUE), length.out = 200)
nd <- setNames(data.frame(xseq), xname)
ic <- predict(fit, newdata = nd, interval = "confidence")
ip <- predict(fit, newdata = nd, interval = "prediction")
plot_df <- data.frame(x = xseq, fit = ic[,"fit"],
lwr_c = ic[,"lwr"], upr_c = ic[,"upr"],
lwr_p = ip[,"lwr"], upr_p = ip[,"upr"])
ggplot() +
geom_point(data = df, aes_string(x = xname, y = "G3"), alpha = 0.7) +
geom_line(data = plot_df, aes(x = x, y = fit), color = "steelblue", linewidth = 1) +
geom_ribbon(data = plot_df, aes(x = x, ymin = lwr_c, ymax = upr_c, fill = "IC media"), alpha = 0.25) +
geom_ribbon(data = plot_df, aes(x = x, ymin = lwr_p, ymax = upr_p, fill = "IP individual"), alpha = 0.12) +
scale_fill_manual(values = c("IC media"="steelblue","IP individual"="red")) +
labs(title = titulo, x = xname, y = "G3") + theme_light()
}
bands_plot(por_num, fit_por, x_por, sprintf("POR: IC (media) vs IP (individual) — G3 ~ %s", x_por))
bands_plot(mat_num, fit_mat, x_mat, sprintf("MAT: IC (media) vs IP (individual) — G3 ~ %s", x_mat))
```

## Analisis de datos atipicos o influyentes


```{r influentes-tablas, echo=FALSE, message=FALSE, warning=FALSE}

library(dplyr)
library(broom)
library(knitr)
library(ggplot2)

# Función: tabla de Cook + marcadores
cook_table <- function(fit, data, modelo){
  n  <- nrow(model.frame(fit))
  k  <- length(coef(fit)) - 1               # predictores (sin intercepto); aquí k=1
  thr <- 4 / (n - k - 1)                    # umbral 4/(n-k-1)
  ct <- tibble(
    obs        = seq_len(n),
    cook       = cooks.distance(fit),
    leverage   = hatvalues(fit),
    rstudent   = rstudent(fit),
    fitted     = fitted(fit),
    resid      = resid(fit),
    flag_cook  = cook > thr,
    flag_rstud = abs(rstudent) > 3,
    flag_lev   = leverage > (2*(k+1)/n)     # regla típica de leverage alto
  ) %>%
    arrange(desc(cook)) %>%
    mutate(model = modelo, thr_cook = thr)
  list(tbl = ct, thr = thr)
}

# Tablas POR & MAT
por_cook <- cook_table(fit_por, por_num, "POR")
mat_cook <- cook_table(fit_mat, mat_num, "MAT")

# Mostrar top-10 con banderas
kable(head(por_cook$tbl, 10),
      caption = sprintf("Tabla 7. Top-10 distancia de Cook — %s (umbral 4/(n−k−1)=%.4f)", 
                        "POR", por_cook$thr),
      digits = 4)

kable(head(mat_cook$tbl, 10),
      caption = sprintf("Tabla 8. Top-10 distancia de Cook — %s (umbral 4/(n−k−1)=%.4f)", 
                        "MAT", mat_cook$thr),
      digits = 4)

# Resumen de cuántos superan umbral y/o son atípicos
resumen <- bind_rows(
  por_cook$tbl %>% summarise(model="POR",
                             n= n(),
                             cook_flag = sum(flag_cook),
                             rstud_flag= sum(flag_rstud),
                             lev_flag  = sum(flag_lev),
                             max_cook  = max(cook)),
  mat_cook$tbl %>% summarise(model="MAT",
                             n= n(),
                             cook_flag = sum(flag_cook),
                             rstud_flag= sum(flag_rstud),
                             lev_flag  = sum(flag_lev),
                             max_cook  = max(cook))
)
kable(resumen, caption="Tabla 9. Resumen de observaciones marcadas (Cook, residuo estudentizado, leverage)")

# (Opcional) gráfico tipo “lollipop” de Cook
plot_cook <- function(ct, titulo){
  ggplot(ct %>% mutate(idx = row_number()) %>% head(30),
         aes(x = reorder(sprintf("#%s", obs), cook), y = cook)) +
    geom_segment(aes(xend = reorder(sprintf("#%s", obs), cook), y = 0, yend = cook)) +
    geom_point() +
    geom_hline(yintercept = ct$thr_cook[1], linetype = 2) +
    coord_flip() + labs(x = "Observación (ordenada por Cook)", y = "Cook's D", title = titulo) +
    theme_light()
}
plot_cook(por_cook$tbl, "Top-30 Cook — POR")
plot_cook(mat_cook$tbl, "Top-30 Cook — MAT")

```


## Discusion y conclusiones
El modelo de regresión lineal simple entre G3 (nota final) y G2 (nota del segundo periodo) muestra una relación lineal fuerte, positiva y estadísticamente significativa. El coeficiente de pendiente (β₁ = 1.0185, p < 0.001) indica que, en promedio, por cada punto adicional en G2, la nota final G3 aumenta en aproximadamente un punto.

El coeficiente de determinación (R² = 0.84) sugiere que G2 explica el 84% de la variabilidad de G3, lo que demuestra un excelente ajuste. Los residuos presentan baja dispersión (σ = 1.28), y el análisis de varianza confirma la significancia del modelo (F = 3493.3, p < 0.001).

En conclusión, el rendimiento del estudiante en el segundo periodo académico (G2) es un excelente estimador de su nota final (G3), lo cual valida la hipótesis inicial de relación lineal entre ambas variables.

Los gráficos de intervalos de confianza y predicción muestran que existe una relación lineal positiva y fuerte entre las calificaciones del segundo (G2) y tercer período (G3) tanto en Portugués como en Matemáticas.
Las bandas de confianza son angostas, lo que indica alta precisión en la estimación de la media.
Las bandas de predicción son más amplias, reflejando la variabilidad individual esperada.
En ambos casos, la mayoría de los puntos se encuentran dentro de las bandas, lo que confirma la validez del modelo lineal simple y la capacidad predictiva de G2 sobre G3.



