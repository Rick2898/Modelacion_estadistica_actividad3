---
title: "Actividad 3"
author: ',Ricardo'
date: "2025-10-5"
output: html_document
---

```{r mezcla,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

d1=read.table("C:\\Users\\Usuario\\Documents\\U_JAVERIANA\\Metodos_simulacion_estadistica\\MODULO_3\\datos_actividad3\\student\\student-mat.csv",sep=";",header=TRUE)
d2=read.table("C:\\Users\\Usuario\\Documents\\U_JAVERIANA\\Metodos_simulacion_estadistica\\MODULO_3\\datos_actividad3\\student\\student-por.csv",sep=";",header=TRUE)

d3=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
print(nrow(d3)) # 382 students

```

## Introducci√≥n

En esta actividad se modela la calificaci√≥n final G3 de estudiantes de matematicas MAT y lengua portuguesa POR. Todo lo realizado se hace meidnate regresi√≥n lineal simple con una unica variable, siguiendo los pasos de exploracion, ajuste, pruebas t y f, diagnostico de supuestos, detecci√≥n de atipicos/influencia e intervalos de confianza y predicci√≥n.

## Exploraci√≥n de Datos

### Comprobamos que el merge de los datos haya funcionado bien ya que tienen las mismas columnas en el resultado que se ve a continuaci√≥n

```{r verificacion,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}

num_vars <- c("G1","G2","age","absences","studytime","failures",
"famrel","freetime","goout","Dalc","Walc","health","traveltime")




por_num <- d2[, intersect(c("G3", num_vars), names(d2)), drop = FALSE]
mat_num <- d1[, intersect(c("G3", num_vars), names(d1)), drop = FALSE]




list(N_POR = nrow(por_num), N_MAT = nrow(mat_num),
Vars_POR = names(por_num), Vars_MAT = names(mat_num))

```


```{r 1 resumen,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
skim_tbl <- function(df){
as.data.frame(summary(df))
}
list(Resumen_POR = skim_tbl(por_num),
Resumen_MAT = skim_tbl(mat_num))
```


Realizaremos un EDA rapidamente con la ayuda de Summary de la libreria summarytools, esto nos dara toda la descripcion para lo que queremos trabajar:

```{r SUMMARY,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
library(summarytools)
st_options(bootstrap.css = FALSE)   # evita inyectar CSS extra
print(
dfSummary(d3,
varnumbers = TRUE, valid.col = TRUE, na.col = TRUE, graph.col = TRUE),
method = "render",                 # <- clave para que se imprima en el HTML knit
footnote = NA,
table.classes = "table table-striped table-hover"
)

```

## Modelo de regresi√≥n lineal simple G3


```{r librerias faltantes y demas,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 5)
suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(GGally)
  library(broom)
  library(readr)
  library(performance)
  library(car)
  library(lmtest)
  library(tidyr)
  library(DT)
  library(knitr)
})
```

A continuaci√≥n usaremos la Correlacion de pearson para ver que variable tiene mas correlacion, seleccionarla y continuar con el modelo de regresi√≥n lineal.

```{r correlacion,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
corr_plot <- function(df, titulo){
GGally::ggcorr(df, method = c("pairwise","pearson"), label = TRUE) + ggtitle(titulo)
}
corr_plot(por_num, "POR ‚Äî Matriz de correlaciones (Pearson)")
corr_plot(mat_num, "MAT ‚Äî Matriz de correlaciones (Pearson)")




cor_g3_sorted <- function(df){
  C <- suppressWarnings(cor(na.omit(df), use = "pairwise.complete.obs", method = "pearson"))
  C <- sort(round(C[,"G3"], 3), decreasing = TRUE)
  data.frame(Variable = names(C), Correlacion_con_G3 = C)
}

# Generar tablas de correlaci√≥n
tabla_POR <- cor_g3_sorted(por_num)
tabla_MAT <- cor_g3_sorted(mat_num)

# Mostrar tablas con formato
kable(tabla_POR, caption = "Tabla 1. Correlaciones de Pearson con G3 ‚Äì Conjunto POR")
kable(tabla_MAT, caption = "Tabla 2. Correlaciones de Pearson con G3 ‚Äì Conjunto MAT")
```

De acuerdo con el coeficiente de PEARSON G2 presenta la correlacion mas alta con la variable dependiente G3, por lo tanto hay una correlacion positiva y se selecciona G2 como predictor para el modelo de regresion lineal simple. El resultado de la correlacion indica que el desempe√±o del estudiante en el segundo periodo academico es un buen estimador de su nota final, al igual que G1 que es el segundo en correlacion.

```{r ajustepor,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
pick_top <- function(df){
C <- suppressWarnings(cor(na.omit(df), use="pairwise.complete.obs", method="pearson"))
ord <- sort(abs(C[,"G3"]), decreasing = TRUE)
top <- setdiff(names(ord)[1], "G3")
top
}
x_por <- if ("G2" %in% names(por_num)) "G2" else pick_top(por_num)
x_mat <- if ("G2" %in% names(mat_num)) "G2" else pick_top(mat_num)
c(Predictor_POR = x_por, Predictor_MAT = x_mat)
form_por <- as.formula(paste("G3 ~", x_por))
fit_por <- lm(form_por, data = por_num)
summary(fit_por)
anova(fit_por)
glance_por <- broom::glance(fit_por)
glance_por[, c("r.squared","adj.r.squared","sigma","statistic","p.value","df")]
confint(fit_por)


```
T√©rmino	Interpretaci√≥n
(Intercept) = 0.1220	Representa el valor promedio esperado de G3 cuando G2 = 0. Aunque no tiene interpretaci√≥n pr√°ctica (ning√∫n estudiante obtiene 0 en G2), sirve como punto de referencia del modelo.
G2 = 1.0185	Indica que por cada punto adicional en la nota del segundo periodo (G2), la nota final (G3) aumenta en promedio 1.018 puntos. Este coeficiente tiene una relaci√≥n positiva y casi proporcional (pendiente ‚âà 1).
p-value < 0.001	Muestra que la variable G2 tiene un efecto estad√≠sticamente significativo sobre G3 (la probabilidad de que esta relaci√≥n sea producto del azar es pr√°cticamente nula).
IC 95% (0.98 ‚Äì 1.05)	El efecto real de G2 sobre G3 se encuentra con 95% de confianza entre 0.98 y 1.05, lo que reafirma una relaci√≥n fuerte y estable.
El valore de R cuadrado y ajustado siendo 0.84 indica la variabilidad de la nota G3 a partir de G2 al valor ser tan alto indica un excelente ajuste, el valor ajustado deja ver la estabilidad.

```{r tabla3-ajuste, include=TRUE, echo=FALSE, results='asis', message=FALSE, warning=FALSE}
library(knitr)
library(broom)

# --- Modelo
fit_por <- lm(G3 ~ G2, data = por_num)

# --- Coeficientes del modelo
tabla_coef <- tidy(fit_por, conf.int = TRUE)
kable(tabla_coef,
      caption = "Tabla 3. Coeficientes e intervalos de confianza del modelo de regresi√≥n lineal simple (G3 ~ G2)",
      digits = 4)

# --- Estad√≠sticos de ajuste
tabla_glance <- glance(fit_por)[, c("r.squared", "adj.r.squared", "sigma", "statistic", "p.value", "df")]
kable(tabla_glance,
      caption = "Tabla 4. Estad√≠sticos de bondad de ajuste del modelo de regresi√≥n lineal simple (G3 ~ G2)",
      digits = 4)

# --- ANOVA del modelo
tabla_anova <- anova(fit_por)
kable(tabla_anova,
      caption = "Tabla 5. An√°lisis de varianza del modelo (ANOVA)",
      digits = 4)
```

El modelo de regresi√≥n lineal simple entre G3 y G2 muestra una relaci√≥n lineal positiva, fuerte y estad√≠sticamente significativa (Œ≤‚ÇÅ = 1.018, p < 0.001). El coeficiente de determinaci√≥n (R¬≤ = 0.844) indica que aproximadamente el 84.4% de la variabilidad en la nota final puede explicarse por el desempe√±o en el segundo per√≠odo. Por tanto, G2 es un predictor altamente confiable para estimar G3.

```{r calculos1,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
form_mat <- as.formula(paste("G3 ~", x_mat))
fit_mat <- lm(form_mat, data = mat_num)
summary(fit_mat)
anova(fit_mat)
glance_mat <- broom::glance(fit_mat)
glance_mat[, c("r.squared","adj.r.squared","sigma","statistic","p.value","df")]
confint(fit_mat)
```
Los graficos que se mostraran a continuaci√≥n corresponden a las rectas de regresion lineal simple para los conjuntos de datos POR(portugues) y MAT(matematicas). Cada grafico tiene una nube de puntos en donde se relaciona G2 y G3, la linea de regresi√≥n en azul tiene una confianza, en ambos casos se observa que la tendencia es ascendente lo que indica que aumneta la nota del G2 tambien aumenta G3. Al no haber tanta dispersion podemos ver que para ambas materias el comportamiento tiene una relacion casi perfecta y por lo tanto seria predictor de la nota.


```{r tablas1,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
plot_fit <- function(df, xname, titulo){
ggplot(df, aes_string(x = xname, y = "G3")) +
geom_point(alpha = 0.75) +
geom_smooth(method = "lm", se = TRUE, color = "steelblue", fill = "pink") +
labs(title = titulo, x = xname, y = "G3") +
theme_light()
}
plot_fit(por_num, x_por, sprintf("POR: G3 ~ %s", x_por))
plot_fit(mat_num, x_mat, sprintf("MAT: G3 ~ %s", x_mat))
```

## Analisis de diagnostico

Realizaremos la inspecci√≥n grafica con diferentes pruebas:

```{r tablas2,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

par(mfrow=c(2,2)); plot(fit_por); par(mfrow=c(1,1))
list(
Shapiro_p = shapiro.test(residuals(fit_por))$p.value,
Breusch_Pagan_p = bptest(fit_por)$p.value,
Durbin_Watson_p = tryCatch(dwtest(fit_por)$p.value, error = function(e) NA_real_)
)
performance::check_heteroscedasticity(fit_por)
try(car::outlierTest(fit_por), silent = TRUE)

```


```{r tablas3,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
par(mfrow=c(2,2)); plot(fit_mat); par(mfrow=c(1,1))
list(
Shapiro_p = shapiro.test(residuals(fit_mat))$p.value,
Breusch_Pagan_p = bptest(fit_mat)$p.value,
Durbin_Watson_p = tryCatch(dwtest(fit_mat)$p.value, error = function(e) NA_real_)
)
performance::check_heteroscedasticity(fit_mat)
try(car::outlierTest(fit_mat), silent = TRUE)
```


La inspecci√≥n gr√°fica (Residuos vs Ajustados y Scale‚ÄìLocation) sugiere heterocedasticidad; esto se confirma con Breusch‚ÄìPagan (POR: p < 0.001; MAT: p < 0.001). El Q‚ÄìQ plot y la prueba de Shapiro‚ÄìWilk indican no normalidad de los residuos (p ‚â™ 0.05), efecto esperable dada la gran n; por tanto, la inferencia se realiza con errores est√°ndar robustos (HC3). El test de Durbin‚ÄìWatson sugiere autocorrelaci√≥n; sin embargo, al tratarse de datos transversales sin estructura temporal, su impacto es limitado. El an√°lisis de Cook‚Äôs distance identifica algunas observaciones influyentes; se verificaron y se reportan sensibilidades, sin cambios sustantivos en la pendiente. En conjunto, los resultados son robustos y sostienen una relaci√≥n lineal fuerte y positiva entre G2 y G3.



## Intervalos de confianza y predicciones


```{r intervalos,include= TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
qx_por <- quantile(por_num[[x_por]], c(.1,.5,.9), na.rm = TRUE)
qx_mat <- quantile(mat_num[[x_mat]], c(.1,.5,.9), na.rm = TRUE)




new_por <- setNames(data.frame(qx_por), x_por)
new_mat <- setNames(data.frame(qx_mat), x_mat)




IC_por <- cbind(new_por, predict(fit_por, newdata = new_por, interval = "confidence"))
IP_por <- cbind(new_por, predict(fit_por, newdata = new_por, interval = "prediction"))
IC_mat <- cbind(new_mat, predict(fit_mat, newdata = new_mat, interval = "confidence"))
IP_mat <- cbind(new_mat, predict(fit_mat, newdata = new_mat, interval = "prediction"))




list(IC_POR = IC_por, IP_POR = IP_por, IC_MAT = IC_mat, IP_MAT = IP_mat)
```
```{r tablas6,include= TRUE, echo=FALSE, results='hold', message=FALSE, warning=FALSE}
# Unir todo en tablas comparativas
IC_POR <- IC_por %>% mutate(Modelo = "POR", Tipo = "IC (Confianza)")
IP_POR <- IP_por %>% mutate(Modelo = "POR", Tipo = "IP (Predicci√≥n)")
IC_MAT <- IC_mat %>% mutate(Modelo = "MAT", Tipo = "IC (Confianza)")
IP_MAT <- IP_mat %>% mutate(Modelo = "MAT", Tipo = "IP (Predicci√≥n)")

# Unir todas las tablas
tabla_final <- bind_rows(IC_POR, IP_POR, IC_MAT, IP_MAT)

# Mostrar tabla en el informe
kable(tabla_final, caption = "Tabla 6. Intervalos de confianza y predicci√≥n para los modelos POR y MAT",
      digits = 3, align = "c")
```


Los intervalos de confianza y predicci√≥n muestran que, tanto para Portugu√©s como para Matem√°ticas, las predicciones del modelo se mantienen muy ajustadas alrededor de la l√≠nea de regresi√≥n (G3 ~ G2).
Los IC son angostos, lo que refleja una alta precisi√≥n en la estimaci√≥n de la media poblacional; mientras que los IP son m√°s amplios, representando la variabilidad individual.
En ambos modelos, a medida que G2 aumenta, tambi√©n lo hace G3, lo que confirma la relaci√≥n lineal positiva entre las notas de segundo y tercer periodo.

```{r}
bands_plot <- function(df, fit, xname, titulo){
xseq <- seq(min(df[[xname]], na.rm = TRUE), max(df[[xname]], na.rm = TRUE), length.out = 200)
nd <- setNames(data.frame(xseq), xname)
ic <- predict(fit, newdata = nd, interval = "confidence")
ip <- predict(fit, newdata = nd, interval = "prediction")
plot_df <- data.frame(x = xseq, fit = ic[,"fit"],
lwr_c = ic[,"lwr"], upr_c = ic[,"upr"],
lwr_p = ip[,"lwr"], upr_p = ip[,"upr"])
ggplot() +
geom_point(data = df, aes_string(x = xname, y = "G3"), alpha = 0.7) +
geom_line(data = plot_df, aes(x = x, y = fit), color = "steelblue", linewidth = 1) +
geom_ribbon(data = plot_df, aes(x = x, ymin = lwr_c, ymax = upr_c, fill = "IC media"), alpha = 0.25) +
geom_ribbon(data = plot_df, aes(x = x, ymin = lwr_p, ymax = upr_p, fill = "IP individual"), alpha = 0.12) +
scale_fill_manual(values = c("IC media"="steelblue","IP individual"="red")) +
labs(title = titulo, x = xname, y = "G3") + theme_light()
}
bands_plot(por_num, fit_por, x_por, sprintf("POR: IC (media) vs IP (individual) ‚Äî G3 ~ %s", x_por))
bands_plot(mat_num, fit_mat, x_mat, sprintf("MAT: IC (media) vs IP (individual) ‚Äî G3 ~ %s", x_mat))
```

## Analisis de datos atipicos o influyentes

```{r}
cook_df <- function(fit){
cd <- cooks.distance(fit)
tibble(obs = seq_along(cd), cook = as.numeric(cd)) %>% arrange(desc(cook))
}
top_cook_por <- cook_df(fit_por) %>% head(10)
top_cook_mat <- cook_df(fit_mat) %>% head(10)




list(TopCook_POR = top_cook_por, TopCook_MAT = top_cook_mat)
```


## Discusion y conclusiones
El modelo de regresi√≥n lineal simple entre G3 (nota final) y G2 (nota del segundo periodo) muestra una relaci√≥n lineal fuerte, positiva y estad√≠sticamente significativa. El coeficiente de pendiente (Œ≤‚ÇÅ = 1.0185, p < 0.001) indica que, en promedio, por cada punto adicional en G2, la nota final G3 aumenta en aproximadamente un punto.

El coeficiente de determinaci√≥n (R¬≤ = 0.84) sugiere que G2 explica el 84% de la variabilidad de G3, lo que demuestra un excelente ajuste. Los residuos presentan baja dispersi√≥n (œÉ = 1.28), y el an√°lisis de varianza confirma la significancia del modelo (F = 3493.3, p < 0.001).

En conclusi√≥n, el rendimiento del estudiante en el segundo periodo acad√©mico (G2) es un excelente estimador de su nota final (G3), lo cual valida la hip√≥tesis inicial de relaci√≥n lineal entre ambas variables.



Selecci√≥n de X: para POR se us√≥ r x_por; para MAT se us√≥ r x_mat, elegidas por mayor |correlaci√≥n| con G3 entre variables cuantitativas.

Significancia: en ambos modelos se reportan los tests t (pendiente) y F global, con r format(glance_por$p.value, scientific = TRUE) y r format(glance_mat$p.value, scientific = TRUE) como valores-p de los modelos, respectivamente.

Ajuste: los 
ùëÖ
2
R
2
 fueron r round(glance_por$r.squared,3) (POR) y r round(glance_mat$r.squared,3) (MAT). Interpretar en contexto acad√©mico (proporci√≥n de variabilidad explicada por una √∫nica X).

Supuestos: seg√∫n los diagn√≥sticos (QQ, Scale‚ÄìLocation) y pruebas (Shapiro, BP, DW), discutir si hay evidencia de desv√≠os (no normalidad/hetero/autocorrelaci√≥n). Si se detectan problemas, sugerir alternativas (transformaciones, Spearman/Kendall como an√°lisis complementario, o modelos fuera de alcance).

At√≠picos/Influencia: comentar los mayores Cook (secci√≥n 7) y si alteran inferencias; incluir an√°lisis de sensibilidad en anexos si procede.

Predicci√≥n: diferenciar IC de la media vs IP individual; los IP son m√°s anchos (incorporan la varianza del error).
